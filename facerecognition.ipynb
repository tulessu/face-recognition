{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: azure-cognitiveservices-vision-face in c:\\users\\handan\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: msrest>=0.5.0 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-face) (0.6.19)\n",
      "Requirement already satisfied, skipping upgrade: azure-common~=1.1 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-face) (1.1.26)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: requests~=2.16 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\handan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\handan\\anaconda3\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.12.0)\n",
      "Please write your urlhttps://static.wikia.nocookie.net/seinfeld/images/5/55/340px-Jerryseinfe.jpg/revision/latest?cb=20120427201915\n",
      "\n",
      "Detected face ID from latest?cb=20120427201915 :\n",
      "5e24daa2-c6d9-4871-92c9-e170ee8f1419\n",
      "\n",
      "Facial attributes detected:\n",
      "Age:  43.0\n",
      "Gender:  Gender.male\n",
      "Head pose:  {'additional_properties': {}, 'roll': -2.6, 'yaw': -7.9, 'pitch': -4.5}\n",
      "Smile:  0.33\n",
      "Facial hair:  {'additional_properties': {}, 'moustache': 0.1, 'beard': 0.1, 'sideburns': 0.1}\n",
      "Glasses:  GlassesType.no_glasses\n",
      "Emotion: \n",
      "\tAnger:  0.0\n",
      "\tContempt:  0.0\n",
      "\tDisgust:  0.0\n",
      "\tFear:  0.0\n",
      "\tHappiness:  0.33\n",
      "\tNeutral:  0.67\n",
      "\tSadness:  0.0\n",
      "\tSurprise:  0.0\n",
      "\n",
      "Drawing rectangle around face... see popup for results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-cognitiveservices-vision-face\n",
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
    "from io import BytesIO\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from azure.cognitiveservices.vision.face.models import FaceAttributeType\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "\n",
    "# Set the FACE_SUBSCRIPTION_KEY environment variable with your key as the value.\n",
    "# This key will serve all examples in this document.\n",
    "KEY = \"1fb6fbd67d4049f6a63bfbd3691bb02f\"\n",
    "\n",
    "# Set the FACE_ENDPOINT environment variable with the endpoint from your Face service in Azure.\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = \"https://tucefacerecognition.cognitiveservices.azure.com/\"\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "\n",
    "\n",
    "# Image of face(s)\n",
    "face1_url = input(\"Please write your url\")\n",
    "face1_name = os.path.basename(face1_url)\n",
    "\n",
    "\n",
    "# List of url images\n",
    "url_images = [face1_url]\n",
    "\n",
    "# Attributes you want returned with the API call, a list of FaceAttributeType enum (string format)\n",
    "face_attributes = ['age', 'gender', 'headPose', 'smile', 'facialHair', 'glasses', 'emotion']\n",
    "\n",
    "# Detect a face with attributes, returns a list[DetectedFace]\n",
    "for image in url_images:\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, return_face_attributes=face_attributes)\n",
    "    if not detected_faces:\n",
    "        raise Exception(\n",
    "            'No face detected from image {}'.format(os.path.basename(image)))\n",
    "\n",
    "    \n",
    "    # Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
    "    for face in detected_faces:\n",
    "        print()\n",
    "        print('Detected face ID from', os.path.basename(image), ':')\n",
    "        # ID of detected face\n",
    "        print(face.face_id)\n",
    "        # Show all facial attributes from the results\n",
    "        print()\n",
    "        print('Facial attributes detected:')\n",
    "        print('Age: ', face.face_attributes.age)\n",
    "        print('Gender: ', face.face_attributes.gender)\n",
    "        print('Head pose: ', face.face_attributes.head_pose)\n",
    "        print('Smile: ', face.face_attributes.smile)\n",
    "        print('Facial hair: ', face.face_attributes.facial_hair)\n",
    "        print('Glasses: ', face.face_attributes.glasses)\n",
    "        print('Emotion: ')\n",
    "        print('\\tAnger: ', face.face_attributes.emotion.anger)\n",
    "        print('\\tContempt: ', face.face_attributes.emotion.contempt)\n",
    "        print('\\tDisgust: ', face.face_attributes.emotion.disgust)\n",
    "        print('\\tFear: ', face.face_attributes.emotion.fear)\n",
    "        print('\\tHappiness: ', face.face_attributes.emotion.happiness)\n",
    "        print('\\tNeutral: ', face.face_attributes.emotion.neutral)\n",
    "        print('\\tSadness: ', face.face_attributes.emotion.sadness)\n",
    "        print('\\tSurprise: ', face.face_attributes.emotion.surprise)\n",
    "        print()\n",
    "\n",
    "    # Convert width height to a point in a rectangle\n",
    "    def getRectangle(faceDictionary):\n",
    "        rect = faceDictionary.face_rectangle\n",
    "        left = rect.left\n",
    "        top = rect.top\n",
    "        right = left + rect.width\n",
    "        bottom = top + rect.height\n",
    "\n",
    "        return ((left, top), (right, bottom))\n",
    "\n",
    "    # Download the image from the url, so can display it in popup/browser\n",
    "    response = requests.get(image)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # For each face returned use the face rectangle and draw a red box.\n",
    "    print('Drawing rectangle around face... see popup for results.')\n",
    "    print()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_faces:\n",
    "        draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "    # Display the image in the users default image browser.\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
